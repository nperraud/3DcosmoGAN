{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import WGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "\n",
    "\n",
    "from cosmotools.metric import evaluation\n",
    "from cosmotools.model import CosmoWGAN\n",
    "from cosmotools.data import load\n",
    "from cosmotools.data import fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 64 # Resolution of the image\n",
    "try_resume = False # Try to resume previous training step\n",
    "Mpch = 350 # Type of dataset (select 70 or 350)\n",
    "\n",
    "\n",
    "forward = fmap.stat_forward\n",
    "backward = fmap.stat_backward\n",
    "def non_lin(x):\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_nbody_dataset(ncubes=10, spix=ns, Mpch=Mpch, forward_map=forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset can return an iterator.\n",
    "it = dataset.iter(10)\n",
    "print(next(it).shape)\n",
    "del it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "X = dataset.get_all_data().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the backward maps invert the forward map.\n",
    "assert(np.sum(np.abs(forward(np.round(backward(X))))-X)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 100)\n",
    "print('min: {}'.format(np.min(X)))\n",
    "print('max: {}'.format(np.max(X)))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free some memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(dataset.get_samples(N=16),nx=4,ny=4);\n",
    "plt.title(\"Real samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_path = 'saved_results'\n",
    "name = 'WGAN{}'.format(ns) + '_' + '2D_simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "md=32\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 2, 2, 1]\n",
    "params_discriminator['nfilter'] = [md, 2*md, 4*md, 2*md, md]\n",
    "params_discriminator['shape'] = [[4, 4],[4, 4],[4, 4], [4, 4], [4, 4]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn ]\n",
    "params_discriminator['full'] = []\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['data_size'] = 2\n",
    "params_discriminator['inception'] = False\n",
    "params_discriminator['spectral_norm'] = False\n",
    "params_discriminator['fft_features'] = False\n",
    "params_discriminator['psd_features'] = False\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [1, 2, 2, 2, 1]\n",
    "params_generator['latent_dim'] = ns*2\n",
    "params_generator['in_conv_shape'] =[ns//8,ns//8]\n",
    "params_generator['nfilter'] = [md, 2*md, 4*md, 2*md, 1]\n",
    "params_generator['shape'] = [[4, 4],[4, 4], [4, 4],[4, 4],[4, 4]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn,bn ]\n",
    "params_generator['full'] = [(ns//8)**2 *8]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = None\n",
    "params_generator['data_size'] = 2\n",
    "params_generator['inception'] = False\n",
    "params_generator['spectral_norm'] = False\n",
    "\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['batch_size'] = 32\n",
    "params_optimization['epoch'] = (ns**2)//64\n",
    "params_optimization['n_critic'] = 5\n",
    "# params_optimization['generator'] = dict()\n",
    "# params_optimization['generator']['optimizer'] = 'adam'\n",
    "# params_optimization['generator']['kwargs'] = {'beta1':0, 'beta2':0.9}\n",
    "# params_optimization['generator']['learning_rate'] = 0.0004\n",
    "# params_optimization['discriminator'] = dict()\n",
    "# params_optimization['discriminator']['optimizer'] = 'adam'\n",
    "# params_optimization['discriminator']['kwargs'] = {'beta1':0, 'beta2':0.9}\n",
    "# params_optimization['discriminator']['learning_rate'] = 0.0001\n",
    "\n",
    "# Cosmology parameters\n",
    "params_cosmology = dict()\n",
    "params_cosmology['forward_map'] = forward\n",
    "params_cosmology['backward_map'] = backward\n",
    "\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['cosmology'] = params_cosmology # Parameters for the cosmological summaries\n",
    "params['net']['prior_distribution'] = 'gaussian'\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['loss_type'] = 'wasserstein' # loss ('hinge' or 'wasserstein')\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 500 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 2000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = (64*32*32)//ns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 10 would be:\n",
    "params['optimization']['epoch'] = 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples\n",
    "To have meaningful statistics, be sure to generate enough samples\n",
    "* 2000 : 32 x 32\n",
    "* 500 : 64 x 64\n",
    "* 200 : 128 x 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 # Number of samples\n",
    "gen_sample = np.squeeze(wgan.generate(N=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(gen_sample,nx=4,ny=4);\n",
    "plt.title(\"Fake samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before computing the statistics, we need to invert the mapping\n",
    "raw_images = backward(dataset.get_samples(2*N))\n",
    "gen_sample_raw = backward(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluation.compute_and_plot_psd(raw_images[:N], gen_sample_raw, confidence='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluation.compute_and_plot_peak_count(raw_images[:N], gen_sample_raw, confidence='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluation.compute_and_plot_mass_hist(raw_images[:N], gen_sample_raw, confidence='std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmotools.metric.score import score_histogram, score_peak_histogram, score_psd\n",
    "print('PSD score: {}'.format(score_psd(raw_images[:N],gen_sample_raw)))\n",
    "print('Histogram score: {}'.format(score_histogram(raw_images[:N],gen_sample_raw)))\n",
    "print('Peak histogram score: {}'.format(score_peak_histogram(raw_images[:N],gen_sample_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For comparizon, the score obtained with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PSD score: {}'.format(score_psd(raw_images[:N],raw_images[N:2*N])))\n",
    "print('Histogram score: {}'.format(score_histogram(raw_images[:N],raw_images[N:2*N])))\n",
    "print('Peak histogram score: {}'.format(score_peak_histogram(raw_images[:N],raw_images[N:2*N])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
